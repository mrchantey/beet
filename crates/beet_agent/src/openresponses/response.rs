//! Response types for the OpenResponses API.
//!
//! This module contains the response body and all related types returned from
//! the `/v1/responses` endpoint.
//!
//! # Example
//!
//! ```no_run
//! use beet_agent::prelude::*;
//! use beet_core::prelude::*;
//! use beet_net::prelude::*;
//!
//! # async fn example() -> Result<()> {
//! dotenv::dotenv().ok();
//!
//! let request_body = openresponses::request::Body::new("gpt-4o-mini")
//!     .with_input("Hello!");
//!
//! let response = Request::post(openresponses::OPENAI_RESPONSES_URL)
//!     .with_auth_bearer(&env_ext::var("OPENAI_API_KEY")?)
//!     .with_json_body(&request_body)?
//!     .send()
//!     .await?
//!     .into_result()
//!     .await?
//!     .json::<openresponses::response::Body>()
//!     .await?;
//!
//! assert_eq!(response.object, "response");
//! assert_eq!(response.status, openresponses::response::Status::Completed);
//!
//! // Extract the first text output
//! if let Some(openresponses::OutputItem::Message(msg)) = response.output.first() {
//!     if let Some(openresponses::OutputContent::OutputText(text)) = msg.content.first() {
//!         println!("Response: {}", text.text);
//!     }
//! }
//! # Ok(())
//! # }
//! ```

use super::*;
use serde::Deserialize;
use serde::Serialize;

/// The response body from the `/v1/responses` endpoint.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Body {
	/// The unique ID of the response.
	pub id: String,
	/// The object type. Always `"response"`.
	pub object: String,
	/// Unix timestamp (seconds) when the response was created.
	pub created_at: i64,
	/// Unix timestamp (seconds) when the response was completed, if completed.
	#[serde(default)]
	pub completed_at: Option<i64>,
	/// The status of the response.
	pub status: Status,
	/// Details about why the response was incomplete, if applicable.
	#[serde(default)]
	pub incomplete_details: Option<IncompleteDetails>,
	/// The model that generated this response.
	pub model: String,
	/// The ID of the previous response in the chain, if any.
	#[serde(default)]
	pub previous_response_id: Option<String>,
	/// Additional instructions that were used to guide the model.
	#[serde(default)]
	pub instructions: Option<String>,
	/// The output items generated by the model.
	pub output: Vec<OutputItem>,
	/// The error that occurred, if the response failed.
	#[serde(default)]
	pub error: Option<Error>,
	/// The tools that were available to the model.
	#[serde(default)]
	pub tools: Vec<FunctionTool>,
	/// The tool choice setting that was used.
	#[serde(default)]
	pub tool_choice: Option<serde_json::Value>,
	/// How the input was truncated by the service.
	#[serde(default)]
	pub truncation: Option<Truncation>,
	/// Whether the model was allowed to call multiple tools in parallel.
	#[serde(default)]
	pub parallel_tool_calls: Option<bool>,
	/// Configuration options for text output that were used.
	#[serde(default)]
	pub text: Option<TextField>,
	/// The nucleus sampling parameter that was used.
	#[serde(default)]
	pub top_p: Option<f64>,
	/// The presence penalty that was used.
	#[serde(default)]
	pub presence_penalty: Option<f64>,
	/// The frequency penalty that was used.
	#[serde(default)]
	pub frequency_penalty: Option<f64>,
	/// The number of most likely tokens returned at each position.
	#[serde(default)]
	pub top_logprobs: Option<u32>,
	/// The sampling temperature that was used.
	#[serde(default)]
	pub temperature: Option<f64>,
	/// Reasoning configuration and outputs.
	#[serde(default)]
	pub reasoning: Option<Reasoning>,
	/// Token usage statistics.
	#[serde(default)]
	pub usage: Option<Usage>,
	/// Maximum tokens the model was allowed to generate.
	#[serde(default)]
	pub max_output_tokens: Option<u32>,
	/// Maximum tool calls the model was allowed to make.
	#[serde(default)]
	pub max_tool_calls: Option<u32>,
	/// Whether this response was stored.
	#[serde(default)]
	pub store: Option<bool>,
	/// Whether this request was run in the background.
	#[serde(default)]
	pub background: Option<bool>,
	/// The service tier that was used.
	#[serde(default)]
	pub service_tier: Option<String>,
	/// Developer-defined metadata associated with the response.
	#[serde(default)]
	pub metadata: Option<serde_json::Value>,
	/// A stable identifier used for safety monitoring.
	#[serde(default)]
	pub safety_identifier: Option<String>,
	/// A key used to read from or write to the prompt cache.
	#[serde(default)]
	pub prompt_cache_key: Option<String>,
}

impl Body {
	/// Returns the first text output from the response, if any.
	pub fn first_text(&self) -> Option<&str> {
		for item in &self.output {
			if let OutputItem::Message(msg) = item {
				for content in &msg.content {
					if let OutputContent::OutputText(text) = content {
						return Some(&text.text);
					}
				}
			}
		}
		None
	}

	/// Returns all text outputs concatenated.
	pub fn all_text(&self) -> String {
		let mut result = String::new();
		for item in &self.output {
			if let OutputItem::Message(msg) = item {
				for content in &msg.content {
					if let OutputContent::OutputText(text) = content {
						result.push_str(&text.text);
					}
				}
			}
		}
		result
	}

	/// Returns all function calls from the response.
	pub fn function_calls(&self) -> Vec<&FunctionCall> {
		self.output
			.iter()
			.filter_map(|item| {
				if let OutputItem::FunctionCall(fc) = item {
					Some(fc)
				} else {
					None
				}
			})
			.collect()
	}

	/// Returns true if the response completed successfully.
	pub fn is_completed(&self) -> bool { self.status == Status::Completed }

	/// Returns true if the response failed.
	pub fn is_failed(&self) -> bool { self.status == Status::Failed }
}

/// Response status.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum Status {
	/// The response is currently being generated.
	InProgress,
	/// The response completed successfully.
	Completed,
	/// The response was incomplete.
	Incomplete,
	/// The response failed.
	Failed,
	/// The response was cancelled.
	Cancelled,
	/// The response is queued.
	Queued,
}

/// Details about why a response was incomplete.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IncompleteDetails {
	/// The reason the response could not be completed.
	pub reason: String,
}

/// An error that occurred during response generation.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Error {
	/// A machine-readable error code.
	pub code: String,
	/// A human-readable description of the error.
	pub message: String,
}

/// Text output configuration in the response.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TextField {
	/// The format configuration.
	pub format: TextFormatField,
	/// The verbosity level.
	#[serde(default)]
	pub verbosity: Option<Verbosity>,
}

/// Text format in the response.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type", rename_all = "snake_case")]
pub enum TextFormatField {
	/// Plain text format.
	Text,
	/// JSON object format.
	#[serde(rename = "json_object")]
	JsonObject,
	/// JSON schema format.
	#[serde(rename = "json_schema")]
	JsonSchema {
		/// The name of the schema.
		name: String,
		/// The description.
		#[serde(default)]
		description: Option<String>,
		/// The schema definition.
		schema: serde_json::Value,
		/// Whether strict mode is enabled.
		#[serde(default)]
		strict: Option<bool>,
	},
}

/// Reasoning configuration and outputs in the response.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Reasoning {
	/// The reasoning effort that was requested.
	#[serde(default)]
	pub effort: Option<ReasoningEffort>,
	/// A model-generated summary of its reasoning.
	#[serde(default)]
	pub summary: Option<ReasoningSummary>,
}


#[cfg(test)]
mod test {
	use super::*;

	#[test]
	fn deserializes_basic_response() {
		let json = r#"{
			"id": "resp_123",
			"object": "response",
			"created_at": 1768969653,
			"completed_at": 1768969655,
			"status": "completed",
			"model": "gpt-4o-mini",
			"output": [
				{
					"type": "message",
					"id": "msg_123",
					"status": "completed",
					"role": "assistant",
					"content": [
						{
							"type": "output_text",
							"text": "Hello!",
							"annotations": []
						}
					]
				}
			],
			"tools": [],
			"usage": {
				"input_tokens": 10,
				"output_tokens": 5,
				"total_tokens": 15,
				"input_tokens_details": {"cached_tokens": 0},
				"output_tokens_details": {"reasoning_tokens": 0}
			}
		}"#;

		let response: Body = serde_json::from_str(json).unwrap();
		assert_eq!(response.id, "resp_123");
		assert_eq!(response.status, Status::Completed);
		assert_eq!(response.first_text(), Some("Hello!"));
	}

	#[test]
	fn deserializes_function_call_response() {
		let json = r#"{
			"id": "resp_456",
			"object": "response",
			"created_at": 1768969653,
			"status": "completed",
			"model": "gpt-4o-mini",
			"output": [
				{
					"type": "function_call",
					"id": "fc_123",
					"call_id": "call_abc",
					"name": "get_weather",
					"arguments": "{\"location\":\"San Francisco\"}",
					"status": "completed"
				}
			],
			"tools": []
		}"#;

		let response: Body = serde_json::from_str(json).unwrap();
		let calls = response.function_calls();
		assert_eq!(calls.len(), 1);
		assert_eq!(calls[0].name, "get_weather");
	}
}

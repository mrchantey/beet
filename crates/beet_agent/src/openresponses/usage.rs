//! Token usage statistics for the OpenResponses API.
//!
//! This module contains types for tracking token consumption during response
//! generation. Usage statistics are essential for monitoring costs and
//! understanding model behavior.
//!
//! # Token Breakdown
//!
//! Usage is reported as:
//! - **Input tokens**: Tokens from your prompt and context
//! - **Output tokens**: Tokens generated by the model
//! - **Total tokens**: Sum of input and output
//!
//! # Token Details
//!
//! Detailed breakdowns include:
//! - **Cached tokens**: Input tokens served from cache (faster, potentially cheaper)
//! - **Reasoning tokens**: Output tokens used for model reasoning (for reasoning models)
//!
//! # Example
//!
//! ```no_run
//! # use beet_agent::prelude::openresponses;
//! # fn example(response: openresponses::ResponseBody) {
//! if let Some(usage) = &response.usage {
//!     println!("Input: {} tokens", usage.input_tokens);
//!     println!("Output: {} tokens", usage.output_tokens);
//!     println!("Total: {} tokens", usage.total_tokens);
//!
//!     if let Some(details) = &usage.input_tokens_details {
//!         println!("Cached: {} tokens", details.cached_tokens);
//!     }
//! }
//! # }
//! ```

use serde::Deserialize;
use serde::Serialize;

/// Token usage statistics recorded for a response.
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct Usage {
	/// The number of input tokens used to generate the response.
	pub input_tokens: u32,
	/// The number of output tokens generated by the model.
	pub output_tokens: u32,
	/// The total number of tokens used.
	pub total_tokens: u32,
	/// A breakdown of input token usage.
	#[serde(default)]
	pub input_tokens_details: Option<InputTokensDetails>,
	/// A breakdown of output token usage.
	#[serde(default)]
	pub output_tokens_details: Option<OutputTokensDetails>,
}

impl Usage {
	/// Creates a new Usage instance.
	pub fn new(input_tokens: u32, output_tokens: u32) -> Self {
		Self {
			input_tokens,
			output_tokens,
			total_tokens: input_tokens + output_tokens,
			input_tokens_details: None,
			output_tokens_details: None,
		}
	}
}

/// A breakdown of input token usage.
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct InputTokensDetails {
	/// The number of input tokens that were served from cache.
	pub cached_tokens: u32,
}

/// A breakdown of output token usage.
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct OutputTokensDetails {
	/// The number of output tokens attributed to reasoning.
	pub reasoning_tokens: u32,
}


#[cfg(test)]
mod test {
	use super::*;

	#[test]
	fn deserializes_usage() {
		let json = r#"{
			"input_tokens": 15,
			"output_tokens": 7,
			"total_tokens": 22,
			"input_tokens_details": {"cached_tokens": 0},
			"output_tokens_details": {"reasoning_tokens": 0}
		}"#;

		let usage: Usage = serde_json::from_str(json).unwrap();
		assert_eq!(usage.input_tokens, 15);
		assert_eq!(usage.output_tokens, 7);
		assert_eq!(usage.total_tokens, 22);
		assert_eq!(usage.input_tokens_details.unwrap().cached_tokens, 0);
		assert_eq!(usage.output_tokens_details.unwrap().reasoning_tokens, 0);
	}

	#[test]
	fn creates_usage() {
		let usage = Usage::new(100, 50);
		assert_eq!(usage.total_tokens, 150);
	}
}
